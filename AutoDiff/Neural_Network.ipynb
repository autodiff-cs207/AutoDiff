{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AutoDiff import DiffObj, Variable, Constant\n",
    "from AutoDiff import MathOps as mo\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(object):\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim, lr=0.1):\n",
    "        self.M = input_dim\n",
    "        self.H = hidden_dim\n",
    "        self.K = out_dim\n",
    "        self.in_var, self.in_val = self.DeclareVariables('x', (1, input_dim))\n",
    "        self.hid_wt_var, self.hid_wt_val = self.DeclareVariables('w', (hidden_dim, input_dim))\n",
    "        self.hid_function = self.AffineLayer(self.in_var[0].values(), self.hid_wt_var, \\\n",
    "                                             activation=True)\n",
    "        self.hid_var, self.hid_val = self.DeclareVariables('h', (1, hidden_dim))\n",
    "        self.out_wt_var, self.out_wt_val = self.DeclareVariables('v', (out_dim, hidden_dim))\n",
    "        self.out_function = self.AffineLayer(self.hid_var[0].values(), self.out_wt_var)\n",
    "        self.out_var, self.out_val = self.DeclareVariables('z', (1, out_dim))\n",
    "        self.out_true_var, self.out_true_val = self.DeclareVariables('y', (out_dim, 1))\n",
    "        self.loss = self.GetLoss('l2')\n",
    "        self.lr = lr\n",
    "    \n",
    "    @classmethod\n",
    "    def Sigmoid(cls, x):\n",
    "        return 1/(1+mo.exp(-x))\n",
    "    \n",
    "    def DeclareVariables(self, base_name, dim):\n",
    "        var = [{base_name + '_' + str(i+1) + ('_' + str(j+1) if dim[1] > 1 else '') : \\\n",
    "               Variable(base_name + '_' + str(i+1) + ('_' + str(j+1) if dim[1] > 1 else '')) \\\n",
    "               for j in range(dim[1])} for i in range(dim[0])]\n",
    "        val_dict = [{base_name + '_' + str(i+1) + ('_' + str(j+1) if dim[1] > 1 else '') : np.random.randn()\\\n",
    "               for j in range(dim[1])} for i in range(dim[0])]\n",
    "        return var, val_dict\n",
    "    \n",
    "    def AffineLayer(self, in_obj, wt_var, activation=False):\n",
    "        layer_out = [None]*len(wt_var)\n",
    "        for idx, node_wt in enumerate(wt_var):\n",
    "            layer_out[idx] = sum(a*b for a,b in zip(in_obj, node_wt.values()))\n",
    "            if activation:\n",
    "                layer_out[idx] = NeuralNet.Sigmoid(layer_out[idx])\n",
    "        return layer_out\n",
    "    \n",
    "    def UpdateParams(self, wt_val, grad):\n",
    "        for w, dw in zip(wt_val, grad):\n",
    "            new_w = np.asarray(list(w.values())) - self.lr*np.asarray(dw)\n",
    "            w.update(zip(w.keys(), new_w))\n",
    "    \n",
    "    def GetLoss(self, loss_fn='l2'):\n",
    "        loss_obj = None\n",
    "        if loss_fn == 'l2':\n",
    "            loss_obj = sum((a*b)**2 for a,b in zip(self.out_true_var[0].values(), \\\n",
    "                                              self.out_var[0].values()))\n",
    "        return loss_obj\n",
    "    \n",
    "    def forward(self, X, y):\n",
    "        self.in_val[0].update(zip(self.in_val[0].keys(), X))\n",
    "        hid_vals = []\n",
    "        for idx, hid_wt in enumerate(self.hid_wt_val):\n",
    "            val_dict = {**self.in_val[0], **hid_wt}\n",
    "            hid_vals += [self.hid_function[idx].get_val(val_dict)]\n",
    "        self.hid_val[0].update(zip(self.hid_val[0].keys(), hid_vals))\n",
    "        out_vals = []\n",
    "        for idx, out_wt in enumerate(self.out_wt_val):\n",
    "            val_dict = {**self.hid_val[0], **out_wt}\n",
    "            out_vals += [self.out_function[idx].get_val(val_dict)]\n",
    "        self.out_val[0].update(zip(self.out_val[0].keys(), out_vals))\n",
    "        self.out_true_val[0].update(zip(self.out_true_val[0].keys(), [y]))\n",
    "        val_dict = {**self.out_val[0], **self.out_true_val[0]}\n",
    "        loss = self.loss.get_val(val_dict)\n",
    "        return loss\n",
    "        \n",
    "    def backward(self):\n",
    "        val_dict = {**self.out_val[0], **self.out_true_val[0]}\n",
    "        dz = self.loss.get_der(val_dict, with_respect_to=self.out_val[0].keys())\n",
    "        dv = []\n",
    "        for idx, out_wt in enumerate(self.out_wt_val):\n",
    "            val_dict = {**self.hid_val[0], **out_wt}\n",
    "            dv += [self.out_function[idx].get_der(val_dict, \\\n",
    "                                                 with_respect_to=out_wt.keys())]\n",
    "        dv =  [list(dz.values())[0]*np.asarray(list(dv[0].values()))]\n",
    "        for idx, h\n",
    "        \n",
    "        self.UpdateParams(self.out_wt_val, dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration of Neural Network\n",
    "input_dim = 3\n",
    "hidden_dim = 5\n",
    "out_dim = 1\n",
    "lr = 0.01\n",
    "nn = NeuralNet(input_dim, hidden_dim, out_dim, lr)\n",
    "\n",
    "X_data = np.random.randn(100, 3)\n",
    "y_data = np.sum(np.multiply(X_data, [1,2,3]), axis=1)\n",
    "num_train = 90\n",
    "X_train, y_train = X_data[0:num_train,:], y_data[0:num_train]\n",
    "X_test, y_test = X_data[num_train:,:], y_data[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 1 is: 97.63\n",
      "Loss after epoch 2 is: 38.05\n",
      "Loss after epoch 3 is: 34.86\n",
      "Loss after epoch 4 is: 27.52\n",
      "Loss after epoch 5 is: 22.27\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    for i in range(X_train.shape[0]):\n",
    "        loss = nn.forward(X_train[i,:], y_train[i])\n",
    "        running_loss += loss\n",
    "        nn.backward()\n",
    "    print('Loss after epoch {} is: {:.2f}'.format(epoch + 1, running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
